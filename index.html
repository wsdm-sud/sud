<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>SUD 2021</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Lato:400,300,700,900" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/animate.css/animate.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Amoeba - v2.0.0
  * Template URL: https://bootstrapmade.com/free-one-page-bootstrap-template-amoeba/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container">

      <div class="logo float-left">
        <!--h1 class="text-light"><a href="index.html"><span>SUD-2021</span></a></h1-->
        <!-- Uncomment below if you prefer to use an image logo -->
        <!-- <a href="index.html"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->
      </div>

      <nav class="nav-menu float-right d-none d-lg-block">
        <ul>
          <li class="active"><a href="#header">Home</a></li>
          <li><a href="#about">Motivation & Description</a></li>
          <li><a href="#track">Call for Papers</a></li>
          <li><a href="#guidelines">Submission Guidelines</a></li>
          <li><a href="#cfp">Call For Papers</a></li>
          <li><a href="#results">Important Dates</a></li>
          <li><a href="#program">Program</a></li>
          <!--li><a href="#contact1">Results</a></li-->
          <li><a href="#team">Organizers</a></li>
        </ul>
      </nav><!-- .nav-menu -->

    </div>
  </header><!-- End #header -->

  <!-- ======= Hero Section ======= -->
  <section id="hero">
    <div class="hero-container">
    <!--div class="call-to-action"-->
      <h2>First International Workshop on </h2>
      <h1><b>S</b>upporting and <b>U</b>nderstanding of Conversational <b>D</b>ialogues (<b>SUD-2021</b>) </h1>
      <h2>Workshop at 14th ACM International Conference on Web Search and Data Mining (<b>WSDM 2021</b>)</h2>
      <a href="#about" class="btn-get-started scrollto">Get Started</a>
    </div>
  </section><!-- #hero -->

  <main id="main">

    <!-- ======= About Us Section ======= -->
    <section id="about" class="about">
      <div class="container">

        <div class="section-title">
            <h2>Workshop Motivation and Description</h2>
        </div>

        <div class="row" >
         <div class="col-lg-6 order-1 order-lg-2">
            <img src="assets/img/conversations.png" class="img-fluid" alt="">
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 order-2 order-lg-1">
            <h3>Motivation</h3>
            <p class="description">
            Verbal communication in the form of spoken dialogues is the most natural and prevalent medium of information exchange between humans. 
              Meetings, prevalent in enterprise environments, are a common communication channel to reach the collective agreements on decision making. 
              Another useful application area of analysis of conversational dialogues is the customer care, where a customer usually interacts with a 
              human or an automated agent (a chatbot) to work towards a specific task. e.g. troubleshoot a Linux workstation etc. 


              <!--A variety of automated processing on the transcripts of these conversational dialogues can be useful in practice, e.g., identification 
              of action items from meetings (specifically, the alternatives discussed and the criteria for each alternative) can help develop effective 
              decision making support systems in enterprises as well as in end-user scenarios. Moreover, applications of NLP and IR methodologies in 
              dialogue based interactive systems, e.g. the need to summarize the meetings, allow provision for ad hoc search on meetings effectively 
              indexing these meetings so that they can be retrieved has increasingly drawn attention from the research community-->.

            </p>
            <br>
        </div>
        </div>

        <div>
            <h3>Description</h3>
            <p class="description">
            There are several open problems in this domain that require an in-depth research such as understanding the <b>nature of conversations</b>, their <b>underlying intent</b> and <b>evaluating</b> the quality of new <b>conversational search tools/algorithms</b>.
            The workshop aims to accomplish the following two goals.
            <ol>
            <li>Gather researchers from the IR and NLP communities to present their recent work on the topic and
            <li>Provide a platform for new PhD students or early researchers to build and evaluate conversational systems on labeled data.
            </ol>

            </p>
            <p>
            The first objective of the proposed <b>SUD workshop series</b> is to bring together researchers from diverse fields –
            <ul>
            <li>
            <b>Information Retrieval</b> </li>
            <li> <b>Data Mining and Machine Learning</b> </li>
            <li><b>Natural Language Processing </b></li>
            <li><b>Human Computer Interaction </b> etc.</li>
            </ul>
            to further advance the state of research in applications and impact of information retrieval to digital two-party or multi-party text or multi-modal dialogues. Given the diverse audience, participants and program of WSDM, it would be an ideal venue to advance research on such topics.

            </p>
            <p></p>
            <!--p>
            It has been established that IR systems can be used to retrieve relevant information either to generate replies in conversations or to add more context about a particular topic during an interactive dialogue between two entities. In addition to inviting work on
            <b>conversational IR </b> and <b>conversational assistive technologies</b>, we specifically focus on an interesting and timely research question that we seek to address as a part of our
data challenge track.
While the regular track invites submissions on both the understanding on and the supporting of conversational dialogues, the data challenge track specifically focuses on the latter. In particular, in order to support conversational dialogues we explore the utility of IR systems to retrieve more information about entities discussed in interactive dialogues. As a continuation of our shared task - RCD1(Retrieval from Conversational Dialogues) organized at FIRE 2020, a large dataset of conversations annotated with underlying user intent is made available. Participants will thus be invited to develop methods for solving practical challenges on the dataset which include detecting user intent in dialogues and retrieving useful information to support these intents.
            </p-->

           <p class="description">
            </p>
      </div>

    </section><!-- End About Us Section -->

    <!-- ======= Services Section ======= -->
    <section id="track" class="portfolio section-bg">
    <div class="container">

        <h1> Call for Papers</h1> 
        <br>
        The proposed workshop will consist of two the following two tracks: 
        <ol>
          <li> <b>Regular Research Paper track </b></li>
          <li> <b>Data Challenge track</b> </li>  
        </ol>
        Following describes each in more details.

        <br>

        <h3>Regular Research Paper Track</h3>
        <br>
        <h4> Themes and Topics aligned with the WSDM 2021 Main Conference CFP </h4>

        We highlight that the following topics are <b>aligned with the WSDM 2021 call for papers</b> on
        <b>Intelligent Assistants </b>, comprising
        <ul>
        <li>Voice search</li>
        <ul><li>conversational search</li> <li>dialog systems</li></ul>
        <li>Personal assistants</li>
        <ul><li>dialogue models</li> <li>conversational interaction</li></ul>
        <!--li>Task-driven search</li>
        <ul><li>Zero-query</li> <li> Implicit search </li> </ul-->
        </ul>

        For authors whose work hasn't been accepted in the main conference, this is a good chance for them to reshape their work and send it to this workshop
        so as to foster discussions on this emerging topic.
        For authors whose papers have already been accepted in the WSDM main conference, they could submit a new work-in-progress
        aligned with their paper in the main conference. 
        <br>

        Other than the topics aligned with the WSDM 2021 main conference as listed above, we also 
              invite contributions related to the main theme of <b>supporting and understanding of conversational
                dialogues</b>, which includes (but is not limited to):
                <menu>
                   <li> Multi-modal and Multi-view Information Retrieval – aggregating information from multiple online and offline data sources 
                           (including text, images, and video) to support conversations.</li>
                   <li> Addressing the code-mixed and noisy, informal vocabulary of conversations.</li>
                   <li> Transfer learning – applying models trained on prior datasets on a new type of conversations.</li>
                   <li> Summarization of conversational dialogues.</li>
                   <li> Information Extraction from conversational dialogues, e.g.extracting action-items, decisions and their criteria from group meetings.</li>
                   <li> <b>Conversational IR</b>, covering topics such as
                     <ul>
                        <li> Retrieving relevant pieces of information corresponding to information needs arising out from conversations.</li>
                        <li> Ways of presenting relevant information through interactive dialogues.</li>
                        <li> Asking clarifying questions to enrich information need description.</li>
                     </ul>
                 </menu>
                </li>
        <br><br>

        <h3>Data Challenge Track </h3>

        <p>The data challenge track is a continuation of our effort to investigate the research question of contextualization of conversational 
           dialogues. We have recently organized a shared task - <b>Retrieval from Conversational Dialogues (RCD) </b> in FIRE 2020 (<a href="https://rcd2020firetask.github.io/RCD2020FIRETASK/">shared task link</a>).
        </p>
                The purpose of the data challenge track is to encourage research on methodologies that are able to proactively recognize potential entities in the conversation that might require 
                further elaboration (from the point-of-view of the user to whom the conversation was targeted)and also retrieves informative content about these 
                entities so to facilitate better participation in the conversation. Although prior work has looked into contextualizing short documents, such as 
                tweets, the proposed data challenge track requires contextualizing the individual aspects of a conversation.
        </p>
           <br>
            <p>
            Papers submitted to this track <b>must</b> report at least one experiment with the released dataset as a part of the RCD track. Authors are encouraged to either
            experiment and report results for the two RCD tasks - that of predicting the text spans from movie dialogues or of retrieving relevant information given a dialog context,
            or reporting experiments on <b>novel tasks on this dataset</b>. 
            </p>

            The call for papers in this track could cover (but are not limited to) the following topics.
            <ol>
            <li>Summarizing conversations.</li>
            <li> Statistical and (deep) ‘Learning to rank’ approaches for Wikipediapassage retrieval.</li>
            <li> Investigate transfer learning of neural models (e.g. trainedon other datasets such as MSMarco) for this task.</li>
            <li> Graph-based techniques (e.g. Graph Convolutional Networks)for passage retrieval.</li>
            <li> Investigate ‘Query Performance Prediction’ (QPP) in thecontext of conversations.</li>
            <li> Investigate the feasibility of applying pre-trained models, e.g.transformer-based language models or transformer architectures fine-tuned on 
              sentence classification or entailmenttasks, to identify the entities requiring contextualizationfrom conversations.</li>
            </ol>
        </div>

      <section id="guidelines" class="call-to-action">
          <div class="container">
        <h2> Submission Guidelines </h2>
        <br>
        Papers submitted for both the <b>regular research</b> and the <b>data challenge</b> tracks should be 4-6 pages of length of content (plus 1 additional page for references). 
Papers must be submitted in PDF according to the new ACM format published in ACM guidelines, selecting the generic <a href="https://www.acm.org/publications/taps/word-template-workflow">sigconf template</a>. The review process is single-blind and therefore submissions should contain author information. Paper should be uploaded via Easychair.

Accepted papers will be included in the SUD 2021 proceedings (companion volume of WSDM 2021) and at least one author of each accepted contribution must attend the workshop.
After acceptance, no additional authors can be added.

        </div>

    </section>
        <section id="program" class="program">
          <div class="container">
             <p>
                <h2>Tentative timeline:</h2>
             <br>
               <h3> Morning session [with a break in between]:</h3>
                  <ul>
                    <li> Keynote talk I [1 hour]</li>
                    <li> Presentation of accepted papers in the regular research papertrack [2.5 hours]</li>
                  </ul>
                <h3>[Lunch break]</h3>
             <br>
              <h3> Afternoon session[with a break in between]: </h3>
               <ul>
                 <li> Keynote talk II [1 hour]</li>
                 <li> Presentation of results and papers of the data challenge track [1.5hours]</li>
                 <li> Panel Discussion [1 hour]</li>
               </ul>
              </p>
              
      </ul>
         </p>
        <!--
        <div class="row">
          <div class="col-lg-4 col-md-6 icon-box">
            <div class="icon"><i class="icofont-computer"></i></div>
            <h4 class="title"><a href="">Lorem Ipsum</a></h4>
            <p class="description">Voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint occaecati cupiditate non provident</p>
          </div>
        </div>
      -->

      </div>
    </section><!-- End Services Section -->

    <!-- ======= Call To Action Section ======= -->
    <!--section id='dataset' class="about">
      <div class="container">

        <div class="text-center">
          <h3>Dataset</h3>
        </div>
        <div>
          <p class='text-left'>
            The movie scripts that were chosen to depict situations requiring contextualization involve relatively long conversations between one or more actors.
            For each movie script, we <b>annotated a span of text</b> that were manually assessed to be indicative of potential contextualization as shown in section above. 
          We selected a number of play-style movie scripts for annotation, i.e. the ones which involve long dialogue acts for plot development. In total, we annotated 4 movie scripts, namely</p>
          <div class="row">
          <div class="col-lg-12">
            <center>
          <ul>
            <li><a href="https://www.imdb.com/title/tt0138704/">Pi</a> </li>
            <li><a href="https://www.imdb.com/title/tt0050083/">12 angry men</a></li>
            <li><a href="https://www.imdb.com/title/tt0119217/">Good will hunting</a></li>
            <li><a href="https://www.imdb.com/title/tt0091605/">The name of the rose</a></li>
            <!--li><a href="https://www.imdb.com/title/tt0049833">The Ten Commandments </a></li>
          </ul>
            </center>
          </div>
            The text extracted from the movie script along with the <a href="https://brat.nlplab.org/"> &nbsp; BRAT &nbsp;</a> formatted annotation file can be found&nbsp;
      <a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/tree/master/dialogues">here</a>.         
          </div>

          <p class='text-left'>
            <!--To facilitate easy participation in the task, we will indexed version of the collection.>
          
        </p-->

        <!--div class='text-left'>
        In the training phase we release 25 dialogue acts making explicitly available the annotated text spans to the participants by marking them up. The participants can then make use the dialogue in order to formulate queries for retrieving relevant passages. 
For task 1 the output will be in the format &lt;qid&gt; &lt;Tab&gt; &lt;Information Need&gt;. Each topic will be in newline. For task 1 the link for the wikipedia collection is here <a href="https://drive.google.com/file/d/1JgiYwTXMkoAUaWzgDeL7LQP5r-G-ReAM/view?usp=sharing">Wikipedia Collection</a>.
        For Task 2, the output format will be same as trec result format. 
        </div-->

        <!--div class='text-left'>
        In the test phase, we will release only the entire dialogue act without the explicit annotation of the precise information need and the relevance judgments (to represent a more realistic situation). The participants are expected to develop and tune their methodologies on the training set and submit the results with optimal configurations of the system on the test set.
        The link for test data set is here <a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/blob/master/test.txt">Test Data</a>.
        </div>

    <p class="text-left">
    <h3> Run Submission Format </h3>
    For each query in the <a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/blob/master/test.txt">test topic file</a>, the participants need to submit automatically generated outputs one or both the tasks.

    <ul>

    <li><b>Task-1:</b> Participants need to submit a two column file where each line contains the query id and the predicted text span from the given description.
    An example task-1 submission file looks like
    <div align="center">
    <pre>
    1 [\t] That's in the Constitution. The Fifth Amendment.
    4 [\t] cute little switchknife
    ...
    ...
    </pre>
    </div>
    </li>

    <li><b>Task-2:</b> Participants need to submit a standard TREC .res formatted file comprising of the following. The first column denotes query id (matches the ids of the test topics), the second is unused, the third is the retrieved document (Wiki passage) identifier, the fourth is the rank of this document (passage), the fifth is the similarity score and the sixth column denotes a run-name to distinguish between different runs (the run-name should be meaningful and representative of the method used to generate the run).
    An example task-2 submission file looks like
    <div align="center">
    <pre>
    1	Q0	10046153-34	1 13.23 BM25_termselection
    1	Q0	10275774-4	2 12.58 BM25_termselection
    ...
    ...
    2	Q0	5202223-19	1 7.64 BM25_termselection
    2	Q0	527390-11	2 7.37 BM25_termselection
    ...
    ...
    </pre>
    </div>
    </ul>    
    </div>

      
    Note that since the retrievable units for our track are Wikipedia passages (not documents), in the collection provided we have assigned unique identifiers
      to passages. The naming convention for a passage is <b>doc number</b>-<b>passage offset</b>, i.e. two integers separated by a hyphen character
      (encoded within the <b>pno</b> tags within the collection provided).
    Task-2 participants will be required to print these identifiers in the third column of the run submission file. Using other arbitrary identifiers
    would not enable us to match the relevant retrieved passages from the ones in the qrel file. A sample XML excerpt for a Wikipedia document, titled
<a href="https://en.wikipedia.org/wiki/Anarchism">Anarchism</a> is shown below. 
</p>
<br>
<br>
<br>

<p>      
<textarea rows="35" cols="80" style="border:none;">
<doc>
 <docno> 2 </docno>
<page>
<p>
 <pno> 2-1 </pno>
    <title>Anarchism</title>
    <ns>0</ns>
    <id>12</id>
    <revision>
      <id>918470367</id>
      <parentid>918111101</parentid>
      <timestamp>2019-09-28T20:40:50Z</timestamp>
      <contributor>
        <username>Brainulator9</username>
        <id>11191612</id>
      </contributor>
      <comment>/* Sources */Remove redundant |year= parameter from CS1 citations;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve">{{good article}}
{{redirect2|Anarchist|Anarchists|other uses|Anarchists (disambiguation)}}
{{pp-move-indef}}
{{short description|Political philosophy that advocates self-governed societies}}
{{use dmy dates|date=July 2018}}
{{use British English|date=January 2014}}
{{anarchism sidebar}}
{{basic forms of government}}
'''Anarchism''' is an [[Anti-authoritarianism|anti-authoritarian]] [[political philosophy]]{{sfnm|1a1=McLaughlin|1y=2007|1p=59|2a1=Flint|2y=2009|2p=27}} that rejects [[Hierarchy|hierarchies]] deemed unjust and advocates their replacement with [[Workers' self-management|self-managed]], [[Self-governance|self-governed]] societies based on voluntary, [[cooperative]] institutions. These institutions are often described as [[Stateless society|stateless societies]],{{sfnm|1a1=Sheehan|1y=2003|1p=85|2a1=Craig|2y=2005|2p=14}} although several authors have defined them more specifically as distinct institutions based on non-hierarchical or [[Free association (communism and anarchism)|free associations]].{{sfn|Suissa|2006|p=7}} Anarchism's central disagreement with other ideologies is that it holds the [[Sovereign state|state]] to be undesirable, unnecessary, and harmful.{{sfnm|1a1=McLean|1a2=McMillan|1y=2003|loc=Anarchism|2a1=Craig|2y=2005|2p=14}}
</p>
</textarea>
  </p>      
     
  <b>For submission, you need to send your runs to rcd2020@firetask@gmail.com. </b>
    </section--><!-- End Call To Action Section -->

    <!-- ======= Our Portfolio Section ======= -->
    <section id="team" class="call-to-action">
      <div class="container">

          <h2>Organizers</h2>

        <div class="row">
          <div class="col-lg-12">
            <ul>
              <li><b><a href='https://gdebasis.github.io/'>Debasis Ganguly </a></b>, IBM Research, Ireland</li>
              <li><b><a href='https://research.yahoo.com/researchers/manishav'>Manisha Verma</a></b>, Yahoo! Research, New York</li>
              <li><b><a href='https://computing.dcu.ie/~sprocheta'>Procheta Sen</a>,</b> Dublin City University, Ireland</li>             
              <li><b><a href='https://computing.dcu.ie/~gjones'>Gareth J.F. Jones</a>,</b> Dublin City University, Ireland</li>             
              <li><b><a href='https://www.isical.ac.in/~dipasree_t/'>Dipasree Pal </a></b>, IRSI, India</li>
              </ul>
          </div>
        </div>


        <div class="section-title">
          <h4>Contact US</h4>
          <p>Please reach out to the organizers for any questions. You can also mail to wsdmconf@gmail.com.</p>
        </div>

      </div>
    </section>  <!-- End Our Portfolio Section -->

    <!-- ======= Frequently Asked Questions Section ======= -->
    <section id="results" class="faq ">
      <div class="container">

        <!--div class="section-title"-->
        <h2>Important Dates</h2>


        <ul>
          <li> Submission deadline - 26th January, 2021 </li>
          <li> Notifications- 23rd February, 2021 </li>
          <li> Camera-Ready - 2nd March, 2021 </li>
          <!--li> Workshop -  March 12, 2021</li-->
        <!--li><strike>Training Data Release</strike> (<a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/tree/master/Train">Download link</a>)-	16th July, 2020   &nbsp;&#10003;</li> 
        <li><strike>Test Data Release</strike> (<a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/blob/master/test.txt">Download link</a>) -	16th July, 2020 &nbsp;&#10003;</li>
        <li>Run Submission Deadline -	5th September, 2020 &nbsp;&#10003;</li>
        <li>Results Declaration -	15th September, 2020 &nbsp;&#10003;</li>
        <li>Working Note Submission -	8th October, 2020</li>
        <li>Review Notifications -	25th October, 2020</li>
        <li>Final Version of Working Note - 5th November, 2020    </li-->    
        </ul>
        
        </div>
        <!--
        <ul class="faq-list">

          <li>
            <a data-toggle="collapse" class="" href="#faq1">Non consectetur a erat nam at lectus urna duis? <i class="icofont-simple-up"></i></a>
            <div id="faq1" class="collapse show" data-parent=".faq-list">
              <p>
                Feugiat pretium nibh ipsum consequat. Tempus iaculis urna id volutpat lacus laoreet non curabitur gravida. Venenatis lectus magna fringilla urna porttitor rhoncus dolor purus non.
              </p>
            </div>
          </li>

          <li>
            <a data-toggle="collapse" href="#faq2" class="collapsed">Feugiat scelerisque varius morbi enim nunc faucibus a pellentesque? <i class="icofont-simple-up"></i></a>
            <div id="faq2" class="collapse" data-parent=".faq-list">
              <p>
                Dolor sit amet consectetur adipiscing elit pellentesque habitant morbi. Id interdum velit laoreet id donec ultrices. Fringilla phasellus faucibus scelerisque eleifend donec pretium. Est pellentesque elit ullamcorper dignissim. Mauris ultrices eros in cursus turpis massa tincidunt dui.
              </p>
            </div>
          </li>

          <li>
           

          <li>
            <a data-toggle="collapse" href="#faq6" class="collapsed">Tortor vitae purus faucibus ornare. Varius vel pharetra vel turpis nunc eget lorem dolor? <i class="icofont-simple-up"></i></a>
            <div id="faq6" class="collapse" data-parent=".faq-list">
              <p>
                Laoreet sit amet cursus sit amet dictum sit amet justo. Mauris vitae ultricies leo integer malesuada nunc vel. Tincidunt eget nullam non nisi est sit amet. Turpis nunc eget lorem dolor sed. Ut venenatis tellus in metus vulputate eu scelerisque. Pellentesque diam volutpat commodo sed egestas egestas fringilla phasellus faucibus. Nibh tellus molestie nunc non blandit massa enim nec.
              </p>
            </div>
          </li>

        </ul>-->

      <!--/div-->
    </section><!-- End Frequently Asked Questions Section -->
      <!--section id="contact1" class="team section-bg">
      <div class="container">

        <div class="section-title">
       </div>
        <div>
          <p class='text-left'>
        The ground-truth for task-1 for the test set topics (comprising of information need requiring Wikification) can be found in the following
          <a href="https://drive.google.com/file/d/17PUCjOPkRZpjydPMrQYCHmbOURyHWuBw/view?usp=sharing">TREC topic formatted file</a>.
          The <b>desc</b> field contains a piece of conversation (from a movie), whereas the <b>title</b> field contains the annotated piece of ground-truth
          text forming the unit of information need.
          </p>
          
          <p class='text-left'>
          While evaluating the results, we took into account overlap for each individual conversational piece (and importantly, not on individual information need unit).
            For example, in the following conversational piece there are two instances of information unit, namely <b>acacia tree</b> and <b>Ming Mecca chip</b>.
            The reference string for this piece is considered to be the concatenation of these two. Also, the predictions for these two topics are concatenated for
            computing the overlap with the ground-truth.
          </p>
            
            <p class='text-center'><font face='courier'>
            Mr. Cohen? Mr. Cohen? Please stop for a second Mr. Cohen?
Damn it already! Stop following me. I'm not interested in your money. I'm searching for a way to understand our world. I'm searching for perfection. I don't deal with mediocre materialistic people like you! ... Take the <font color="red">acacia tree</font>...in East Africa. It is the most prevalent plant in all of Kenya because it has managed to secure its niche by defeating its major predator, the giraffe. To accomplish this, the tree has made a contract with a highly specialized red ant. The tree has evolved giant spores which act as housing for the ants In return for shelter, the ants supply defense. When a giraffe starts to eat the tree's leaves, the shaking branch acts like an alarm. The ants charge out and secrete an acid onto the giraffe's tongue. The giraffe learns its lesson and never returns. Without each other, the tree would be picked .... Just silicon. <font color="blue">A Ming Mecca chip</font>.  
              </font></p>
          <p class='text-left'>          
            To reproduce results for task 1, simply use the <a href="https://github.com/gdebasis/luc4ir/blob/master/rcd/eval.sh">script</a>. Go through
            the github readme to set up the environment. The script only requires the folder for task 1 runs to generate the BLEU score.
          </p>
        <p class='text-left'>
          For task 1, the script uses two pieces of information -
          a) the annotated text for each topic (see <a href="https://github.com/gdebasis/luc4ir/blob/master/rcd/rels_task1.tsv">here</a>) and
          b) the equivalence relation of the topics (see <a href="https://github.com/gdebasis/luc4ir/blob/master/rcd/equiv.txt">here</a>) - to compute the overlap.          
        </p>
          <p class='text-left'>
          For evaluating task 2 runs, please run this <a href='https://github.com/rcd2020firetask/RCD2020FIRETASK/blob/master/eval/equiv_treceval.sh'>script</a> which requires qrels and retrieval runs (formatted as TREC runs) as two inputs. The relevance judgments i.e. qrels are available <a href='https://github.com/rcd2020firetask/RCD2020FIRETASK/blob/master/eval/qrel-judgement-v4.txt'>here</a>. </p>
          
        </div>
        
        </div>
        </section-->
    <!-- ======= Our Team Section ======= -->
    <section id="contact" class="team section-bg">
      <div class="container">

        <!--
        <div class="row">
          <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/team-1.jpg" alt="">
              <h4>Walter White</h4>
              <span>Chief Executive Officer</span>
              <p>
                Magni qui quod omnis unde et eos fuga et exercitationem. Odio veritatis perspiciatis quaerat qui aut aut aut
              </p>
              <div class="social">
                <a href=""><i class="icofont-twitter"></i></a>
                <a href=""><i class="icofont-facebook"></i></a>
                <a href=""><i class="icofont-instagram"></i></a>
                <a href=""><i class="icofont-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/team-2.jpg" alt="">
              <h4>Sarah Jhinson</h4>
              <span>Product Manager</span>
              <p>
                Repellat fugiat adipisci nemo illum nesciunt voluptas repellendus. In architecto rerum rerum temporibus
              </p>
              <div class="social">
                <a href=""><i class="icofont-twitter"></i></a>
                <a href=""><i class="icofont-facebook"></i></a>
                <a href=""><i class="icofont-instagram"></i></a>
                <a href=""><i class="icofont-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/team-3.jpg" alt="">
              <h4>William Anderson</h4>
              <span>CTO</span>
              <p>
                Voluptas necessitatibus occaecati quia. Earum totam consequuntur qui porro et laborum toro des clara
              </p>
              <div class="social">
                <a href=""><i class="icofont-twitter"></i></a>
                <a href=""><i class="icofont-facebook"></i></a>
                <a href=""><i class="icofont-instagram"></i></a>
                <a href=""><i class="icofont-linkedin"></i></a>
              </div>
            </div>
          </div>

        </div>
      -->

      </div>
    </section><!-- End Our Team Section -->

  <!-- ======= Footer ======= -->
  <!--
  <footer id="footer">
    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>Amoeba</span></strong>. All Rights Reserved
      </div>
      <div class="credits">-->
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/free-one-page-bootstrap-template-amoeba/ -->
        <!--Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>
  </footer>--><!-- End #footer -->

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>

