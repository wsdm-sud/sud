<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>SUD 2021</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Lato:400,300,700,900" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/animate.css/animate.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Amoeba - v2.0.0
  * Template URL: https://bootstrapmade.com/free-one-page-bootstrap-template-amoeba/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container">

      <div class="logo float-left">
        <!--h1 class="text-light"><a href="index.html"><span>SUD-2021</span></a></h1-->
        <!-- Uncomment below if you prefer to use an image logo -->
        <!-- <a href="index.html"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->
      </div>

      <nav class="nav-menu float-right d-none d-lg-block">
        <ul>
          <li class="active"><a href="#header">Home</a></li>
          <li><a href="#about">Motivation & Description</a></li>
          <li><a href="#papers">Research Track</a></li>
          <li><a href="#dtrack">Data Challenge Track</a></li>
          <li><a href="#guidelines">Submission Guidelines</a></li>
          <li><a href="#impdates">Important Dates</a></li>
          <li><a href="#program">Program</a></li>
          <!--li><a href="#contact1">Results</a></li-->
          <li><a href="#team">Organizers</a></li>
        </ul>
      </nav><!-- .nav-menu -->

    </div>
  </header><!-- End #header -->

  <!-- ======= Hero Section ======= -->
  <section id="hero">
    <div class="hero-container">
    <!--div class="call-to-action"-->
      <h2>First International Workshop on </h2>
      <h1><b>S</b>upporting and <b>U</b>nderstanding of Conversational <b>D</b>ialogues <br> (<b>SUD-2021</b>) </h1>
      <h2>Workshop at 14th ACM International Conference on Web Search and Data Mining (<b>WSDM 2021</b>)</h2>
      <a href="#about" class="btn-get-started scrollto">Get Started</a>
    </div>
  </section><!-- #hero -->

  <main id="main">

    <!-- ======= About Us Section ======= -->
    <section id="about" class="about">
      <div class="container">

        <div class="section-title">
            <h2>Workshop Motivation and Description</h2>
        </div>

        <div class="row" >
         <div class="col-lg-6 order-1 order-lg-2">
            <img src="assets/img/conversations.png" class="img-fluid" alt="">
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 order-2 order-lg-1">
            <h3>Motivation</h3>
            <p class="description">
            Verbal communication in the form of spoken dialogues is the most natural and prevalent medium of information exchange between humans. 
              Meetings, prevalent in enterprise environments, are a common communication channel to reach the collective agreements on decision making. 
              Another useful application area of analysis of conversational dialogues is the customer care, where a customer usually interacts with a 
              human or an automated agent (a chatbot) to work towards a specific task. e.g. troubleshoot a Linux workstation etc. 


              <!--A variety of automated processing on the transcripts of these conversational dialogues can be useful in practice, e.g., identification 
              of action items from meetings (specifically, the alternatives discussed and the criteria for each alternative) can help develop effective 
              decision making support systems in enterprises as well as in end-user scenarios. Moreover, applications of NLP and IR methodologies in 
              dialogue based interactive systems, e.g. the need to summarize the meetings, allow provision for ad hoc search on meetings effectively 
              indexing these meetings so that they can be retrieved has increasingly drawn attention from the research community-->.

            </p>
            <br>
        </div>
        </div>

        <div>
            <h3>Description</h3>
            <p class="description">
            There are several open problems in this domain that require an in-depth research such as understanding the <b>nature of conversations</b>, their <b>underlying intent</b> and <b>evaluating</b> the quality of new <b>conversational search tools/algorithms</b>.
            The workshop aims to accomplish the following two goals.
            <ol>
            <li>Gather researchers from the IR and NLP communities to present their recent work on the topic and
            <li>Provide a platform for new PhD students or early researchers to build and evaluate conversational systems on labeled data.
            </ol>

            </p>
            <p>
            The first objective of the proposed <b>SUD workshop series</b> is to bring together researchers from diverse fields – Information Retrieval, Data Mining and Machine Learning, Natural Language Processing, , Human Computer Interaction etc. to further advance the state of research in applications and impact of information retrieval to digital two-party or multi-party text or multi-modal dialogues. Given the diverse audience, participants and program of WSDM, it would be an ideal venue to advance research on such topics.

            </p>
            <p></p>
            <!--p>
            It has been established that IR systems can be used to retrieve relevant information either to generate replies in conversations or to add more context about a particular topic during an interactive dialogue between two entities. In addition to inviting work on
            <b>conversational IR </b> and <b>conversational assistive technologies</b>, we specifically focus on an interesting and timely research question that we seek to address as a part of our
data challenge track.
While the regular track invites submissions on both the understanding on and the supporting of conversational dialogues, the data challenge track specifically focuses on the latter. In particular, in order to support conversational dialogues we explore the utility of IR systems to retrieve more information about entities discussed in interactive dialogues. As a continuation of our shared task - RCD1(Retrieval from Conversational Dialogues) organized at FIRE 2020, a large dataset of conversations annotated with underlying user intent is made available. Participants will thus be invited to develop methods for solving practical challenges on the dataset which include detecting user intent in dialogues and retrieving useful information to support these intents.
            </p-->

           <p class="description">
            </p>
      </div>

    </section><!-- End About Us Section -->

    <!-- ======= Services Section ======= -->
    <section id="papers" class="portfolio section-bg">
    <div class="container">
      <h1> Research Track call for papers</h1> 
        The proposed workshop will consist of two tracks a) Research track and b) Data challenge track. 
        Research paper track invites submissions from themes and topics aligned with research in Conversational Dialogues. 

        The following topics associated with Intelligent Assistants are particularly of interest for SUD 2021 workshop: 
        <ul>
        <li>Voice search</li>
        <ul><li>conversational search</li> <li>dialog systems</li></ul>
        <li>Personal assistants</li>
        <ul><li>dialogue models</li> <li>conversational interaction</li></ul>
        <!--li>Task-driven search</li>
        <ul><li>Zero-query</li> <li> Implicit search </li> </ul-->
        </ul>

        <!--For authors whose work hasn't been accepted in the main conference, this is a good chance for them to reshape their work and send it to this workshop
        so as to foster discussions on this emerging topic.
        For authors whose papers have already been accepted in the WSDM main conference, they could submit a new work-in-progress
        aligned with their paper in the main conference. -->

        We also invite contributions related to the main theme of <b>supporting and understanding of conversational dialogues</b>, which includes (but is not limited to):
                <menu>
                  <li> Mining and extracting conversational datasets from the web. </li>
                   <li> Multi-modal and Multi-view Information Retrieval – aggregating information from multiple online and offline data sources (including text, images, and video) to support conversations.</li>
                   <li> Addressing the code-mixed, noisy and informal vocabulary of conversations.</li>
                   <li> Transfer learning – applying models trained on prior datasets to different conversations.</li>
                   <li> Summarization of conversational dialogues.</li>
                   <li> Information Extraction from conversational dialogues, e.g.extracting action-items, decisions and their criteria from group meetings.</li>
                   <li> <b>Conversational IR</b>, covering topics such as
                     <ul>
                        <li> Retrieving relevant pieces of information corresponding to information needs arising out from conversations.</li>
                        <li> Ways of presenting relevant information through interactive dialogues.</li>
                        <li> Asking clarifying questions to enrich information need description.</li>
                     </ul>
                 </menu>
                </li>
        <br><br>
        <section id="dtrack" class="portfolio section-bg">
        <div class="container">
          <h1> Data Challeng</h1> 
           <p>The data challenge track is a continuation of our effort to investigate the research question of contextualization of conversational 
           dialogues.  A shared task was recently organized - <b>Retrieval from Conversational Dialogues (<a href="https://rcd2020firetask.github.io/RCD2020FIRETASK/">RCD</a>) </b> at FIRE 2020.
            </p>
                Data challenge track seeks submissions that investigate both understanding of sample dialogues and support such conversations with more contextual information. 
                As part of the challenge, we are releasing conversational data for two tasks. The first task is to detect entities in these conversations. The second task is to retrieve informative content about these 
                entities to facilitate user understanding. Although prior work has looked into contextualizing short documents, such as 
                tweets, the proposed data challenge track requires contextualizing aspects of a conversation.
            </p>
            <br>
            <p>
            Papers submitted to this track <b>must</b> report at least one experiment with the dataset released as a part of the RCD track. Authors are encouraged to either
            experiment and report results for the two RCD tasks - that of detecting entities in the text spans from movie dialogues or of retrieving relevant information given a dialog context, or reporting experiments on <b>novel tasks on this dataset</b>. 
            </p>

            The call for papers in this track covers (but is not limited to) the following topics.
            <ol>
            <li>Entity linking in dialogues</li>
            <li>Summarizing conversations</li>
            <li> Methods for passage retrieval supporting conversations</li>
            <li> Aoproaches for image retrieval supporting conversations</li>
            <li> Transfer learning to support conversations from different domains</li>
            <li> Graph-based techniques (e.g. Graph Convolutional Networks) to understand conversations</li>
            <li> Investigate ‘Query Performance Prediction’ (QPP) in the context of conversations</li>
            <li> Adaptation of large scale models, e.g.transformer-based language models to contextualize conversations better.</li>
            </ol>
        </div>

      <section id="guidelines" class="call-to-action">
          <div class="container">
        <h2> Submission Guidelines </h2>
        <br>
        Papers submitted for both the <b>regular research</b> and the <b>data challenge</b> tracks should be 4-6 pages of length of content (plus 1 additional page for references). 
Papers must be submitted in PDF according to the new ACM format published in ACM guidelines, selecting the generic <a href="https://www.acm.org/publications/taps/word-template-workflow">sigconf template</a>. The review process is single-blind and therefore submissions should contain author information. Paper should be uploaded via Easychair.

Accepted papers will be included in the SUD 2021 proceedings (companion volume of WSDM 2021) and at least one author of each accepted contribution must attend the workshop.
After acceptance, no additional authors can be added.

        </div>

    <section id="impdates">
      <div class="container">

        <!--div class="section-title"-->
        <h2>Important Dates</h2>


        <ul>
          <li> Submission deadline - 26th January, 2021 </li>
          <li> Notifications- 23rd February, 2021 </li>
          <li> Camera-Ready - 2nd March, 2021 </li>
          <!--li> Workshop -  March 12, 2021</li-->
        <!--li><strike>Training Data Release</strike> (<a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/tree/master/Train">Download link</a>)-	16th July, 2020   &nbsp;&#10003;</li> 
        <li><strike>Test Data Release</strike> (<a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/blob/master/test.txt">Download link</a>) -	16th July, 2020 &nbsp;&#10003;</li>
        <li>Run Submission Deadline -	5th September, 2020 &nbsp;&#10003;</li>
        <li>Results Declaration -	15th September, 2020 &nbsp;&#10003;</li>
        <li>Working Note Submission -	8th October, 2020</li>
        <li>Review Notifications -	25th October, 2020</li>
        <li>Final Version of Working Note - 5th November, 2020    </li-->    
        </ul>
        
        </div>
      </div>
    </section>


    </section>
        <section id="program" class="program">
          <div class="container">
             <p>
                <h2>Tentative timeline:</h2>
             <br>
               <h3> Morning session [with a break in between]:</h3>
                  <ul>
                    <li> Keynote talk I [1 hour]</li>
                    <li> Presentation of accepted papers in the regular research papertrack [2.5 hours]</li>
                  </ul>
                <h3>[Lunch break]</h3>
             <br>
              <h3> Afternoon session[with a break in between]: </h3>
               <ul>
                 <li> Keynote talk II [1 hour]</li>
                 <li> Presentation of results and papers of the data challenge track [1.5hours]</li>
                 <li> Panel Discussion [1 hour]</li>
               </ul>
              </p>
              
      </ul>
         </p>

      </div>
    </section>

    <section id="team" class="call-to-action">
      <div class="container">

          <h2>Organizers</h2>

        <div class="row">
          <div class="col-lg-12">
            <ul>
              <li><b><a href='https://gdebasis.github.io/'>Debasis Ganguly </a></b>, IBM Research, Ireland</li>
              <li><b><a href='https://research.yahoo.com/researchers/manishav'>Manisha Verma</a></b>, Yahoo! Research, New York</li>
              <li><b><a href='https://computing.dcu.ie/~sprocheta'>Procheta Sen</a>,</b> Dublin City University, Ireland</li>             
              <li><b><a href='https://computing.dcu.ie/~gjones'>Gareth J.F. Jones</a>,</b> Dublin City University, Ireland</li>             
              <li><b><a href='https://www.isical.ac.in/~dipasree_t/'>Dipasree Pal </a></b>, IRSI, India</li>
              </ul>
          </div>
        </div>


        <div class="section-title">
          <h4>Contact US</h4>
          <p>Please reach out to the organizers for any questions. You can also mail to wsdmconf@gmail.com.</p>
        </div>

      </div>
    </section>  <!-- End Our Portfolio Section -->

  <!-- ======= Footer ======= -->
  <!--
  <footer id="footer">
    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>Amoeba</span></strong>. All Rights Reserved
      </div>
      <div class="credits">-->
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/free-one-page-bootstrap-template-amoeba/ -->
        <!--Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>
  </footer>--><!-- End #footer -->

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>

