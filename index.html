<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>SUD 2021</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Lato:400,300,700,900" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/animate.css/animate.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Amoeba - v2.0.0
  * Template URL: https://bootstrapmade.com/free-one-page-bootstrap-template-amoeba/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container">

      <div class="logo float-left">
        <h1 class="text-light"><a href="index.html"><span>SUD-2021</span></a></h1>
        <!-- Uncomment below if you prefer to use an image logo -->
        <!-- <a href="index.html"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->
      </div>

      <nav class="nav-menu float-right d-none d-lg-block">
        <ul>
          <li class="active"><a href="#header">Home</a></li>
          <li><a href="#about">Task Description</a></li>
          <li><a href="#services">Guidelines</a></li>
          <li><a href="#dataset">Dataset</a></li>
          <li><a href="#team">Organizers</a></li>
          <li><a href="#results">Important Dates</a></li>
          <li><a href="#contact1">Results</a></li>
          <li><a href="#contact">Contact Us</a></li>
        </ul>
      </nav><!-- .nav-menu -->

    </div>
  </header><!-- End #header -->

  <!-- ======= Hero Section ======= -->
  <section id="hero">
    <div class="hero-container">
      <h1>First International Workshop on </h1>
      <h1>Supporting and Understanding of Conversational Dialogues</h1>
      <h2>Supporting and Understanding of Conversational Dialogues (SUD-2021) </h2>
      <h2> Full-day Workshop at 14th ACM International Conference on Web Search and Data Mining (WSDM 2021) </h2>
      <a href="#about" class="btn-get-started scrollto">Get Started</a>
    </div>
  </section><!-- #hero -->

  <main id="main">

    <!-- ======= About Us Section ======= -->
    <section id="about" class="about">
      <div class="container">

        <div class="section-title">
            <h2>Workshop motivation and description</h2>
        </div>

        <div class="row" >
         <div class="col-lg-6 order-1 order-lg-2">
            <img src="fakechat-B.png" class="img-fluid" alt="">
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 order-2 order-lg-1">
            <h3>Motivation</h3>
            <p class="description">
            Verbal communication in the form of spoken dialogues is the most natural and prevalent medium of information exchange between humans. 
              Meetings, prevalent in enterprise environments, are a common communication channel to reach the collective agreementson decision making. 
              Another useful application area of analysis of conversational dialogues is the customer care, where a customer usually interacts with a 
              human or an automated agent (a chatbot) to work towards a specific task. e.g. troubleshoot a Linux workstation etc. 
              A variety of automated processing on the transcripts of these conversational dialogues can be useful in practice, e.g., identification 
              of action items from meetings (specifically, the alternatives discussed and the criteria for each alternative) can help develop effective 
              decision making support systems in enterprises as well as in end-user scenarios. Moreover, applications of NLP and IR methodologies in 
              dialogue based interactive systems, e.g. the need to summarize the meetings, allow provision for ad hoc search on meetings effectively 
              indexing these meetings so that they can be retrieved has increasingly drawn attention from the research community.
            </p>
            <h3>Description</h3>
            <p class="description">
            There are several open problems in this domain that require anin-depth research such as understanding the nature of conversa-tions, their underlying intent and evaluating the quality of new conversational search tools/algorithms. The workshop aims to ac-complish two goals a) gather researchers from the IR and NLPcommunities to present their recent work on the topic and b) pro-vide a platform for new PhD students or early researchers to buildand evaluate conversational systems on labeled data.
            </p>
            <p>
            The first objective of the proposed SUD workshop series is to bring together researchers from diverse fields – Information Retrieval, Data Mining and Machine Learning, Natural Language Processing and Human Computer Interaction – to further advance the state of research in applications and impact of information retrieval to digital two-party or multi-party text or multi-modal dialogues. Given the diverse audience, participants and program of WSDM, it would be an ideal venue to advance research on such topics.
            </p>
            <p>
            It has been established that IR systems can be used to retrieve relevant information either to generate replies in conversations or to add more context about a particular topic during an interactive dialogue between two entities. In addition to inviting work on conversational IR and conversational assistive technologies, we specifically focus on an interesting and timely research question that we seek to address as a part of our data challenge track. While the regular track invites submissions on both the understanding on and the supporting of conversational dialogues, the data challenge track specifically focuses on the latter. In particular, in order to support conversational dialogues we explore the utility of IR systems to retrieve more information about entities discussed in interactive dialogues. As a continuation of our shared task - RCD1(Retrieval from Conversational Dialogues) organized at FIRE 2020, a large dataset of conversations annotated with underlying user intent is made available. Participants will thus be invited to develop methods for solving practical challenges on the dataset which include detecting user intent in dialogues and retrieving useful information to support these intents.
            </p>
           <p class="description">
            </p>
            <!--
            <ul>
              <li><i class="icofont-check-circled"></i> Ullamco laboris nisi ut aliquip ex ea commodo consequat.</li>
              <li><i class="icofont-check-circled"></i> Duis aute irure dolor in reprehenderit in voluptate velit.</li>
              <li><i class="icofont-check-circled"></i> Ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate trideta storacalaperda mastiro dolore eu fugiat nulla pariatur.</li>
            </ul>
            <p>
              Ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate
              velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in
              culpa qui officia deserunt mollit anim id est laborum
            </p>-->
          </div>
        </div>

      </div>
    </section><!-- End About Us Section -->

    <!-- ======= Services Section ======= -->
    <section id="services" class="about section-bg">
      <div class="container">

        <!--div class="section-title"-->
          <!--h2> Guidelines</h2-->
        <!--/div-->
          <!--p class="description">
          For the SUD track, we have chosen conversations from movie scripts that constitute situations requiring contextualization.
            These are long conversations between one or more actors.
            One such example is the highlighted span of text (requiring contextualization) from the movie <a href="https://www.imdb.com/title/tt0050083/">12 angry men</a>
            as shown below.
          <div class="row">
          <ul class='text-center' >
            <font face='courier'>
              <li><font color='red'> NO2:</font> guilty. I thought it was obvious. I mean nobody proved otherwise.</li>
              <li><font color='blue'> NO8:</font>  is on the prosecution. The defendant doesn’t have to open his mouth. That’s in the Constitution. <font color='green'>The Fifth Amendment</font>. You’ve heard of it.</li>
              <li><font color='red'> NO2:</font>  I... what I meant... well, anyway, I think he was guilty.</li>
            </font>
          </ul>
          </div>
        In the above piece of conversation example, the goal is to develop a system that will identify that Fifth Amendment is the piece of text that may
        require contextualization, and retrieve a ranked list of Wikipedia passages corresponding to this concept.<-->
        <br>
 
        <h3> Theme And Structure Of The Workshop </h3> 
        <br>
        The proposed workshop will consist of two tracks: (1) a regular research paper track, and (2) a data challenge track.  
        <br>
        
        <!--With the main task of retrieving passages corresponding to a dialogue, we also ask the participants to participate optionally
        in a stand-alone information extraction (IE) task, where the objective would be to output the span of text corresponding to the information need.
        A participant could choose one or both of the tasks to participate.-->
        Following are the two tracks. 
          <ul>
              <li><font color='blue'>Track 1:</font> Regular research paper track. </li>
              <li> The regular research paper track will solicit contributions related to the theme of supporting and understanding of conversational
                dialogues, which includes (but is not limited to):
                <menu>
                   <li> Multi-modal and multi-view Information Retrieval – aggregating information from multiple online and offline datasources 
                           (including text, images, and video) to support conversations.</li>
                   <li> Addressing the code-mixed and noisy, informal vocabularyof conversations.</li>
                   <li> Transfer learning – applying models trained on prior datasetson a new type of conversations.</li>
                   <li> Summarization of conversational dialogues.</li>
                   <li> Information Extraction from conversational dialogues, e.g.extracting action-items, decisions and their criteria fromgroup meetings.</li>
                   <li> Conversational IR, covering topics such as
                      <menu>
                        <li> retrieving relevant pieces of information correspondingto information needs arising out from conversations.</li>
                        <li> Ways of presenting relevant information through interactive dialogues.</li>
                        <li> Asking clarifying questions to enrich information needdescription.</li>
                     </menu>
                   </li>
                </menu>
              </li>
              <li><font color='blue'>Track 2:</font> Data challenge track. </li>
              <li> <p>The data challenge track is designed to bring together researchers and practitioners to work on IR-specific problems on conversational 
                dialogues. The objective of the data track is to automatically contextualize a multi-party dialogue system as detailed below.
                </p>
                <p>
                Traditional information retrieval (IR) involves retrieving relevant documents from a collection given a user query (usually comprised of a small number 
                of keywords). With the advancement of automated dialog systems, using IR models as a component in such dialog-based interactive systems has 
                increasingly drawn attention of the research community. Conversational IR is potentially useful to retrieve relevant documents or passages 
                towards constructing an answer for a query/question seeking information on a particular topic during an interactive chat-session. An example 
                use-case is anautomated customer-care chat-bot that seeks to answer a specific user query (e.g. ‘How do I restart my Macbook?’) with a relevant 
                answer (the information feeding in to the relevant answer formulated by either directly retrieving previous responses or constructing them 
                automatically from retrieving candidate passages). 
                </p>
                <p>
                Different from the existing notion of conversational IR, involving retrieving previous responses or passages from a collection to aid an interactive chat-bot, the focus of our work is to supplement information for a particular 
                topic within a two or multi-party dialogue with relevant information that contextualizes the conversation itself. As an example, consider the
                situation when two persons (let us call them A and B) are chatting to each other through a chatserver, e.g. Google Hangouts, Whatsapp etc. 
                It may happen that A talks about a topic or event of which B is not fully aware of. In that case, the chat server (in addition to sending 
                the message from A could contextualize the message with additional information). As a concrete example, with A’s following message -
                </p>
                <p>
                A: “I absolutely loved dark.”,
                </p>
                <p>
                B may have trouble making sense of this sentence in its literal form unless they know that the entity ‘Dark’ in this 
                context refers to a popular Netflix series. However, it could be easier for B to understand and come up with a prompt response to the message 
                if the chat-server provides this additional information to B as apart of the message itself. From the user interface perspective, A may not 
                even be aware of this automatic contextualization by the conversational assistance agent and to them it appears as if B came up with a prompt 
                response. Figure 1 schematically depicts this situation with an example communication between two parties.
                </p>
                <p>
                
                The purpose of the data challenge track thus is to encourage research on methodologies that are able to proactively recognize potential entities in the conversation that might require 
                further elaboration (from the point-of-view of the user to whom the conversation was targeted)and also retrieves informative content about these 
                entities so to facilitate better participation in the conversation. Although prior work has looked into contextualizing short documents, such as 
                tweets, the proposed data challenge track requires contextualizing the individual aspects of a conversation.</li>
          </ul>
        </p>
      
      <h5>Dataset Description </h5>
      <p>
      To study the problem under a laboratory-based reproducible setting, we propose a number of simplifications. First, since collecting multi-party chat dialogues
      can lead to individual privacy concerns, items requiring contextualization. Using movie scripts as a starting point, the task requires participants to retrieve
      relevant information from Wikipedia given a dialogue span from a movie script. The task of the participants is to identify important or central entities in a
      span of movie dialogues and to subsequently retrieve a list of passages that provide more contextor information about entities in that span. The annotated 
      span oftext (i.e. the one requiring contextualization) will not be disclosed to the participants. One such example is the underlined span of text (requiring
      contextualization) from the movie ‘12 angry men’shown as follows.
      </p>
      <p>
      Example-1:A part of dialogue act from the movie ‘12 angry men’.
      <br>
        NO.2:guilty. I thought it was obvious. I mean nobody proved otherwise.
      <br>
        NO. 8:is on the prosecution. The defendant doesn’t have to openhis mouth. That’s in the Constitution. TheFifth Amendment.You’ve heard of it.
      <br>
        NO. 2:  I... what I meant... well, anyway, I think he was guilty.
      </p>
      <p>
        We selected a number of play-style movie scripts for annotation, i.e.the ones which involve long dialogue acts for plot development.The participants 
        are provided with a manually annotated sample of dialogue spans extracted from four movie scripts along with entire movie scripts. The collection from 
        which passages are to be retrieved for contextualization is the Wikipedia collection (dump from 2019). Each document in the Wikipedia collection is 
        composed of explicitly marked-up passages (in the form of the paragraph tags).The retrievable units in our task are the passages (instead of 
        whole documents).
      </p>
      <ul>
        <li> <font color='blue'> Tasks. </font> Based on the two different threads of potential research investigation with the dataset, we will invite 
          participation in two distinct tasks. Each participating team can participate in any one or both the tasks described as follows.
          <menu> 
            <li><font color='blue'>Task 1:</font> Given an excerpt of a dialogue act (as shown in Example-1), output the span of text indicating a potential piece
              of information need (requiring contextualization), i.e.,in  case  of  the  example,  output  the  underlined  text  Fifth Amendment. To evaluate 
              this task of information extraction, we propose to use a character n-gram based weighted BLEU score to compute the overlap of the ground-truth 
              text span (e.g. ‘fifth amendment’) and the predicted text span (e.g.‘Constitution. The Fifth Amendment’).</li>
            <li><font color='blue'>Task 2:</font> Given an excerpt of a dialogue act (see above example), return a ranked list of passages containing 
              informationon the topic requiring contextualization, i.e., with respect to the above example return passages from Wikipedia that contain 
              information on the Fifth Amendment. For this task, we will use mean average precision (MAP) and mean reciprocal rank (MRR) to compare and 
              evaluate different approaches. These metrics would favour systems that retrieve a higher number of relevant passages towards the top ranks. 
              A dataset comprising the document collection of Wikipedia passages, a set of 50 topics corresponding to excerpts from movie scripts, a set of 
              ground-truth entities judged to be requiring contextualization along with relevance judgments for each is made publicly available at the 
              RCD track webpage.<li>
            </menu>
        <li> <font color='blue'> Call for papers in the Data Challenge Track.</font> In addition tosubmitting working notes for experiments conducted to 
          address the two proposed tasks of extracting potential snippets requiring contextualization (Task-1) and retrieving a ranked list of Wikipedia 
          passages for each identified segment (Task-2), we also invite researchers to submit their work on other research directions conducted on this 
          dataset. The call for papers in this track could correspond to (but are not limited to) the following topics.
          <ol>
            <li>Summarizing conversations.</li>
            <li> Statistical and (deep) ‘Learning to rank’ approaches for Wikipediapassage retrieval.</li>
            <li> Investigate transfer learning of neural models (e.g. trainedon other datasets such as MSMarco) for this task.</li>
            <li> Graph-based techniques (e.g. Graph Convolutional Networks)for passage retrieval.</li>
            <li> Investigate ‘Query Performance Prediction’ (QPP) in thecontext of conversations.</li>
            <li> Investigate the feasibility of applying pre-trained models, e.g.transformer-based language models or transformer architectures fine-tuned on 
              sentence classification or entailmenttasks, to identify the entities requiring contextualizationfrom conversations.</li>
          </ol>
         Thus, participating groups will have the opportunity to submit two types of peer-reviewed papers as a part of the data challenge track: (1) 
          full-length research papers describing the research questions they investigated during the track and associated results/insights, and (2) short 
          papers summarizing participation efforts. Accepted full papers will have a presentation slot during the workshop, while short papers will also be given an 
          oral/posterpresentation slot. We anticipate participation from a wide range of internationalresearch groups who might be interested in this data challenge
          given the popularity of the general topic of conversational IR. 
        </li>
      </ul>
        <h3>Workshop Format (Half/Full-day) And Planned Activities</h3>
         <p class="description">
           We propose a <font color='blue'> full-day workshop</font>. The workshop will include presentation of papers accepted through peer-review and results of the data challenge track, 
           keynote talks, and discussion sessions on open and upcoming challenges on the theme of the workshop. 
           <p>
           Peer-review track: In the peer-review track, there will be two types of papers – full papers of 5-6 pages (to be presented orally for 20 minutes) and
             short papers of at most 2 pages (to be presented orally for 10 minutes and/or through posters). We encourage submission of novel work-in-progress 
             papers that show promising directions, to facilitate discussion during the workshop. We also encourage papers that demonstrate systems that can be
             practically useful for supporting conversations. We will look to accept 8-10 papers (including full and short papers) through a peer-review 
             process, where every submission will be reviewed by at least two members of a competent Program Committee. 
             </p>
             <p>
             Data challenge track: The participating teams will be invitedto submit full/short papers, which will also be peer-reviewed by members of the PC. 
               In addition, there will be a working note reporting the experiments and the results of the data challenge track. 
             </p>
             <p>
             Keynote talks: The workshop will include at least two keynote talks by reputed researchers working on topics related to the workshop theme. We will 
                attempt to have talks from both academic researchers and practitioners who are actually engaged in conducting research on the related research 
                topics.
             </p>
             <p>
              Selection process for participants: As stated earlier, all submitted papers of the peer-review track as well as the data challenge track will be 
                peer-reviewed by at least two members of a competent program committee, consisting of members from the academia as well as from the industry. 
                Authors of the accepted papers will be invited to attend the workshop. Participation in the workshop will be open to all interested registered 
                participants.
              </p>
           </p>
             <p>
                <h2>Tentative timeline:</h2>
             <br>
               <h3> Morning session [with a break in between]:</h3>
                  <ul>
                    <li> Keynote talk I [1 hour]</li>
                    <li> Presentation of accepted papers in the regular research papertrack [2.5 hours]</li>
                  </ul>
                <h3>[Lunch break]</h3>
             <br>
              <h3> Afternoon session[with a break in between]: </h3>
               <ul>
                 <li> Keynote talk II [1 hour]</li>
                 <li> Presentation of results and papers of the data challenge track [1.5hours]</li>
                 <li> Panel Discussion [1 hour]</li>
               </ul>
              </p>
              
      </ul>
         </p>
        <!--
        <div class="row">
          <div class="col-lg-4 col-md-6 icon-box">
            <div class="icon"><i class="icofont-computer"></i></div>
            <h4 class="title"><a href="">Lorem Ipsum</a></h4>
            <p class="description">Voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint occaecati cupiditate non provident</p>
          </div>
        </div>
      -->

      </div>
    </section><!-- End Services Section -->

    <!-- ======= Call To Action Section ======= -->
    <!--section id='dataset' class="about">
      <div class="container">

        <div class="text-center">
          <h3>Dataset</h3>
        </div>
        <div>
          <p class='text-left'>
            The movie scripts that were chosen to depict situations requiring contextualization involve relatively long conversations between one or more actors.
            For each movie script, we <b>annotated a span of text</b> that were manually assessed to be indicative of potential contextualization as shown in section above. 
          We selected a number of play-style movie scripts for annotation, i.e. the ones which involve long dialogue acts for plot development. In total, we annotated 4 movie scripts, namely</p>
          <div class="row">
          <div class="col-lg-12">
            <center>
          <ul>
            <li><a href="https://www.imdb.com/title/tt0138704/">Pi</a> </li>
            <li><a href="https://www.imdb.com/title/tt0050083/">12 angry men</a></li>
            <li><a href="https://www.imdb.com/title/tt0119217/">Good will hunting</a></li>
            <li><a href="https://www.imdb.com/title/tt0091605/">The name of the rose</a></li>
            <!--li><a href="https://www.imdb.com/title/tt0049833">The Ten Commandments </a></li>
          </ul>
            </center>
          </div>
            The text extracted from the movie script along with the <a href="https://brat.nlplab.org/"> &nbsp; BRAT &nbsp;</a> formatted annotation file can be found&nbsp;
      <a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/tree/master/dialogues">here</a>.         
          </div>

          <p class='text-left'>
            <!--To facilitate easy participation in the task, we will indexed version of the collection.-->
        The dataset for this track comprises of:
        <ul>
        <li> <b>Document Collection</b>: The objective in this track (Task-2) is to retrieve a ranked list of Wikipedia passages. We release a pre-processed version of Wikipedia
dump, where we have enclosed each paragraph of a Wikipedia page into separate XML tags. Each tag is assigned a unique identifier. The basic retrieval unit for this ranking
task is hence a Wikipedia passage. Note that it's up to you if you want to treat the passages as units contained within a document or treat them independently while ranking them.
Each passage has been (and will be) judged independently.
          
          There are two options for the collection that you can download.
          <ul>
          <li> A TREC formatted markup document that for the passage demarcated Wikipedia collection from this
<a href="https://drive.google.com/file/d/1JgiYwTXMkoAUaWzgDeL7LQP5r-G-ReAM/view?usp=sharing">Google drive link</a>.
          </li>
          <li> A more simplified format (a tab separated file text file) containing the passage id in the first column and passage content in the second.
                    You can get the gzipped file from this <a href="https://drive.google.com/file/d/1iujCKja301ciGnk3nvErUJebF7_Tc7pD/view?usp=sharing">Google drive link</a>.
          </li>
          </ul>
          
          A sample mavenized Lucene project to help the participants get started with indexing and retrieval can be found
          <a href="https://github.com/gdebasis/luc4ir">here</a>.
          
        </li>
        <li> <b> Queries/Topics: </b> A query for the ranking task contains a dialog piece from a movie. The topic file is similar in structure to a standard TREC query.
        Each query (topic) starts with a <b>topic</b> tag. The <b>num</b> tag assigns a unique identifier to the topic. You have to use these ids in the output <b>results</b>
file (more on this later). Each topic has a <b>desc</b> tag which contains a list of dialogues enclosed within '<b>p</b>' tags. Each 'p' tag indicates a change of speaker.
Some topics have identical description fields because while annotating we identified multiple concepts from the same dialog piece that may require contextualization.
In such a case, the one with a smaller number is associated to the concept which occurs in the text before the other corresponding to the larger number.
In addition to the 'desc' field, the training topics contains an additional <b>title </b> field which describes the exact span of text representing the information need.
We make this information available for the participants to get an idea about the types of text spans that would typically require contextualization from dialog streams.

        </li>
        <li><b>Relevance Judgments: </b> For the training set of topics, we release a <b>TREC qrel</b> formatted file with 4 white-space separated columns, the first column
denoting query id, the second unused, the third - a string denoting the passage (basic retrieval unit) identifier and the fourth indicating the relevance label (1/0) in our case.
The training topics along with the relevance judgments can be downloaded from this <a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/tree/master/Train">link to training data</a>. To obtain the relevance assessments, we constructed a pool of passages by a combination of retrieval with a number of standard IR models, such as BM25, LM, DFR etc. Passages in the pool were assessed by the organizors with respect to each input dialogue.
For test topics, we will add the documents collected from the participating systems in the pool and
reevaluate the extended pool.
        </li>
        </ul>
          
        </p>

        <!--div class='text-left'>
        In the training phase we release 25 dialogue acts making explicitly available the annotated text spans to the participants by marking them up. The participants can then make use the dialogue in order to formulate queries for retrieving relevant passages. 
For task 1 the output will be in the format &lt;qid&gt; &lt;Tab&gt; &lt;Information Need&gt;. Each topic will be in newline. For task 1 the link for the wikipedia collection is here <a href="https://drive.google.com/file/d/1JgiYwTXMkoAUaWzgDeL7LQP5r-G-ReAM/view?usp=sharing">Wikipedia Collection</a>.
        For Task 2, the output format will be same as trec result format. 
        </div-->

        <!--div class='text-left'>
        In the test phase, we will release only the entire dialogue act without the explicit annotation of the precise information need and the relevance judgments (to represent a more realistic situation). The participants are expected to develop and tune their methodologies on the training set and submit the results with optimal configurations of the system on the test set.
        The link for test data set is here <a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/blob/master/test.txt">Test Data</a>.
        </div>

    <p class="text-left">
    <h3> Run Submission Format </h3>
    For each query in the <a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/blob/master/test.txt">test topic file</a>, the participants need to submit automatically generated outputs one or both the tasks.

    <ul>

    <li><b>Task-1:</b> Participants need to submit a two column file where each line contains the query id and the predicted text span from the given description.
    An example task-1 submission file looks like
    <div align="center">
    <pre>
    1 [\t] That's in the Constitution. The Fifth Amendment.
    4 [\t] cute little switchknife
    ...
    ...
    </pre>
    </div>
    </li>

    <li><b>Task-2:</b> Participants need to submit a standard TREC .res formatted file comprising of the following. The first column denotes query id (matches the ids of the test topics), the second is unused, the third is the retrieved document (Wiki passage) identifier, the fourth is the rank of this document (passage), the fifth is the similarity score and the sixth column denotes a run-name to distinguish between different runs (the run-name should be meaningful and representative of the method used to generate the run).
    An example task-2 submission file looks like
    <div align="center">
    <pre>
    1	Q0	10046153-34	1 13.23 BM25_termselection
    1	Q0	10275774-4	2 12.58 BM25_termselection
    ...
    ...
    2	Q0	5202223-19	1 7.64 BM25_termselection
    2	Q0	527390-11	2 7.37 BM25_termselection
    ...
    ...
    </pre>
    </div>
    </ul>    
    </div>

      
    Note that since the retrievable units for our track are Wikipedia passages (not documents), in the collection provided we have assigned unique identifiers
      to passages. The naming convention for a passage is <b>doc number</b>-<b>passage offset</b>, i.e. two integers separated by a hyphen character
      (encoded within the <b>pno</b> tags within the collection provided).
    Task-2 participants will be required to print these identifiers in the third column of the run submission file. Using other arbitrary identifiers
    would not enable us to match the relevant retrieved passages from the ones in the qrel file. A sample XML excerpt for a Wikipedia document, titled
<a href="https://en.wikipedia.org/wiki/Anarchism">Anarchism</a> is shown below. 
</p>
<br>
<br>
<br>

<p>      
<textarea rows="35" cols="80" style="border:none;">
<doc>
 <docno> 2 </docno>
<page>
<p>
 <pno> 2-1 </pno>
    <title>Anarchism</title>
    <ns>0</ns>
    <id>12</id>
    <revision>
      <id>918470367</id>
      <parentid>918111101</parentid>
      <timestamp>2019-09-28T20:40:50Z</timestamp>
      <contributor>
        <username>Brainulator9</username>
        <id>11191612</id>
      </contributor>
      <comment>/* Sources */Remove redundant |year= parameter from CS1 citations;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve">{{good article}}
{{redirect2|Anarchist|Anarchists|other uses|Anarchists (disambiguation)}}
{{pp-move-indef}}
{{short description|Political philosophy that advocates self-governed societies}}
{{use dmy dates|date=July 2018}}
{{use British English|date=January 2014}}
{{anarchism sidebar}}
{{basic forms of government}}
'''Anarchism''' is an [[Anti-authoritarianism|anti-authoritarian]] [[political philosophy]]{{sfnm|1a1=McLaughlin|1y=2007|1p=59|2a1=Flint|2y=2009|2p=27}} that rejects [[Hierarchy|hierarchies]] deemed unjust and advocates their replacement with [[Workers' self-management|self-managed]], [[Self-governance|self-governed]] societies based on voluntary, [[cooperative]] institutions. These institutions are often described as [[Stateless society|stateless societies]],{{sfnm|1a1=Sheehan|1y=2003|1p=85|2a1=Craig|2y=2005|2p=14}} although several authors have defined them more specifically as distinct institutions based on non-hierarchical or [[Free association (communism and anarchism)|free associations]].{{sfn|Suissa|2006|p=7}} Anarchism's central disagreement with other ideologies is that it holds the [[Sovereign state|state]] to be undesirable, unnecessary, and harmful.{{sfnm|1a1=McLean|1a2=McMillan|1y=2003|loc=Anarchism|2a1=Craig|2y=2005|2p=14}}
</p>
</textarea>
  </p>      
     
  <b>For submission, you need to send your runs to rcd2020@firetask@gmail.com. </b>
    </section--><!-- End Call To Action Section -->

    <!-- ======= Our Portfolio Section ======= -->
    <section id="team" class="portfolio section-bg">
      <div class="container">

        <div class="section-title">
          <h2>Organizers</h2>

        </div>
        <div class="row">
          <div class="col-lg-12">
            <ul >
              <li ><a href='https://gdebasis.github.io/'>Debasis Ganguly </a>, IBM Research, Ireland</li>
              <li ><a href='https://research.yahoo.com/researchers/manishav'>Manisha Verma</a>, Yahoo! Research, New York</li>
              <li ><a href='https://computing.dcu.ie/~sprocheta'>Procheta Sen</a>, Dublin City University, Ireland</li>             
              <li ><a href='https://computing.dcu.ie/~gjones'>Gareth J.F. Jones</a>, Dublin City University, Ireland</li>             
              <li ><a href='https://www.isical.ac.in/~dipasree_t/'>Dipasree Pal </a>, IRSI, India</li>
              </ul>
          </div>
        </div>
        <!--
        <div class="row">
          <div class="col-lg-12">
            <ul id="portfolio-flters">
              <li data-filter="*" class="filter-active">All</li>
              <li data-filter=".filter-app">App</li>
              <li data-filter=".filter-card">Card</li>
              <li data-filter=".filter-web">Web</li>
            </ul>
          </div>
        </div>
        

        <div class="row portfolio-container">
  <div class="col-lg-4 col-md-6 filter-web">
            <div class="portfolio-item">
              <img src="assets/img/portfolio/portfolio-9.jpg" class="img-fluid" alt="">
              <div class="portfolio-info">
                <h3><a href="assets/img/portfolio/portfolio-9.jpg" data-gall="portfolioGallery" class="venobox" title="Web 1">Web 1</a></h3>
                <a href="assets/img/portfolio/portfolio-9.jpg" data-gall="portfolioGallery" class="venobox" title="Web 1"><i class="icofont-plus"></i></a>
              </div>
            </div>
          </div>

        </div>-->

      </div>
    </section><!-- End Our Portfolio Section -->

    <!-- ======= Frequently Asked Questions Section ======= -->
    <section id="results" class="faq ">
      <div class="container">

        <div class="section-title">
        <h2>Important Dates</h2>


        <ul>
          <li> Submission deadline - 26th January, 2021 </li>
          <li> Notifications- 23rd February, 2021 </li>
          <li> Camera-Ready - 2nd March, 2021 <li>
          <!--li> Workshop -  March 12, 2021</li-->
        <!--li><strike>Training Data Release</strike> (<a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/tree/master/Train">Download link</a>)-	16th July, 2020   &nbsp;&#10003;</li> 
        <li><strike>Test Data Release</strike> (<a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/blob/master/test.txt">Download link</a>) -	16th July, 2020 &nbsp;&#10003;</li>
        <li>Run Submission Deadline -	5th September, 2020 &nbsp;&#10003;</li>
        <li>Results Declaration -	15th September, 2020 &nbsp;&#10003;</li>
        <li>Working Note Submission -	8th October, 2020</li>
        <li>Review Notifications -	25th October, 2020</li>
        <li>Final Version of Working Note - 5th November, 2020    </li-->    
        </ul>
        
        </div>
        <!--
        <ul class="faq-list">

          <li>
            <a data-toggle="collapse" class="" href="#faq1">Non consectetur a erat nam at lectus urna duis? <i class="icofont-simple-up"></i></a>
            <div id="faq1" class="collapse show" data-parent=".faq-list">
              <p>
                Feugiat pretium nibh ipsum consequat. Tempus iaculis urna id volutpat lacus laoreet non curabitur gravida. Venenatis lectus magna fringilla urna porttitor rhoncus dolor purus non.
              </p>
            </div>
          </li>

          <li>
            <a data-toggle="collapse" href="#faq2" class="collapsed">Feugiat scelerisque varius morbi enim nunc faucibus a pellentesque? <i class="icofont-simple-up"></i></a>
            <div id="faq2" class="collapse" data-parent=".faq-list">
              <p>
                Dolor sit amet consectetur adipiscing elit pellentesque habitant morbi. Id interdum velit laoreet id donec ultrices. Fringilla phasellus faucibus scelerisque eleifend donec pretium. Est pellentesque elit ullamcorper dignissim. Mauris ultrices eros in cursus turpis massa tincidunt dui.
              </p>
            </div>
          </li>

          <li>
           

          <li>
            <a data-toggle="collapse" href="#faq6" class="collapsed">Tortor vitae purus faucibus ornare. Varius vel pharetra vel turpis nunc eget lorem dolor? <i class="icofont-simple-up"></i></a>
            <div id="faq6" class="collapse" data-parent=".faq-list">
              <p>
                Laoreet sit amet cursus sit amet dictum sit amet justo. Mauris vitae ultricies leo integer malesuada nunc vel. Tincidunt eget nullam non nisi est sit amet. Turpis nunc eget lorem dolor sed. Ut venenatis tellus in metus vulputate eu scelerisque. Pellentesque diam volutpat commodo sed egestas egestas fringilla phasellus faucibus. Nibh tellus molestie nunc non blandit massa enim nec.
              </p>
            </div>
          </li>

        </ul>-->

      <!--/div-->
    </section><!-- End Frequently Asked Questions Section -->
      <!--section id="contact1" class="team section-bg">
      <div class="container">

        <div class="section-title">
       </div>
        <div>
          <p class='text-left'>
        The ground-truth for task-1 for the test set topics (comprising of information need requiring Wikification) can be found in the following
          <a href="https://drive.google.com/file/d/17PUCjOPkRZpjydPMrQYCHmbOURyHWuBw/view?usp=sharing">TREC topic formatted file</a>.
          The <b>desc</b> field contains a piece of conversation (from a movie), whereas the <b>title</b> field contains the annotated piece of ground-truth
          text forming the unit of information need.
          </p>
          
          <p class='text-left'>
          While evaluating the results, we took into account overlap for each individual conversational piece (and importantly, not on individual information need unit).
            For example, in the following conversational piece there are two instances of information unit, namely <b>acacia tree</b> and <b>Ming Mecca chip</b>.
            The reference string for this piece is considered to be the concatenation of these two. Also, the predictions for these two topics are concatenated for
            computing the overlap with the ground-truth.
          </p>
            
            <p class='text-center'><font face='courier'>
            Mr. Cohen? Mr. Cohen? Please stop for a second Mr. Cohen?
Damn it already! Stop following me. I'm not interested in your money. I'm searching for a way to understand our world. I'm searching for perfection. I don't deal with mediocre materialistic people like you! ... Take the <font color="red">acacia tree</font>...in East Africa. It is the most prevalent plant in all of Kenya because it has managed to secure its niche by defeating its major predator, the giraffe. To accomplish this, the tree has made a contract with a highly specialized red ant. The tree has evolved giant spores which act as housing for the ants In return for shelter, the ants supply defense. When a giraffe starts to eat the tree's leaves, the shaking branch acts like an alarm. The ants charge out and secrete an acid onto the giraffe's tongue. The giraffe learns its lesson and never returns. Without each other, the tree would be picked .... Just silicon. <font color="blue">A Ming Mecca chip</font>.  
              </font></p>
          <p class='text-left'>          
            To reproduce results for task 1, simply use the <a href="https://github.com/gdebasis/luc4ir/blob/master/rcd/eval.sh">script</a>. Go through
            the github readme to set up the environment. The script only requires the folder for task 1 runs to generate the BLEU score.
          </p>
        <p class='text-left'>
          For task 1, the script uses two pieces of information -
          a) the annotated text for each topic (see <a href="https://github.com/gdebasis/luc4ir/blob/master/rcd/rels_task1.tsv">here</a>) and
          b) the equivalence relation of the topics (see <a href="https://github.com/gdebasis/luc4ir/blob/master/rcd/equiv.txt">here</a>) - to compute the overlap.          
        </p>
          <p class='text-left'>
          For evaluating task 2 runs, please run this <a href='https://github.com/rcd2020firetask/RCD2020FIRETASK/blob/master/eval/equiv_treceval.sh'>script</a> which requires qrels and retrieval runs (formatted as TREC runs) as two inputs. The relevance judgments i.e. qrels are available <a href='https://github.com/rcd2020firetask/RCD2020FIRETASK/blob/master/eval/qrel-judgement-v4.txt'>here</a>. </p>
          
        </div>
        
        </div>
        </section-->
    <!-- ======= Our Team Section ======= -->
    <section id="contact" class="team section-bg">
      <div class="container">

        <div class="section-title">
          <h2>Contact US</h2>
          <p>Please reach out to the organizers for any questions. You can also mail to wsdmconf@gmail.com.</p>
        </div>
        <!--
        <div class="row">
          <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/team-1.jpg" alt="">
              <h4>Walter White</h4>
              <span>Chief Executive Officer</span>
              <p>
                Magni qui quod omnis unde et eos fuga et exercitationem. Odio veritatis perspiciatis quaerat qui aut aut aut
              </p>
              <div class="social">
                <a href=""><i class="icofont-twitter"></i></a>
                <a href=""><i class="icofont-facebook"></i></a>
                <a href=""><i class="icofont-instagram"></i></a>
                <a href=""><i class="icofont-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/team-2.jpg" alt="">
              <h4>Sarah Jhinson</h4>
              <span>Product Manager</span>
              <p>
                Repellat fugiat adipisci nemo illum nesciunt voluptas repellendus. In architecto rerum rerum temporibus
              </p>
              <div class="social">
                <a href=""><i class="icofont-twitter"></i></a>
                <a href=""><i class="icofont-facebook"></i></a>
                <a href=""><i class="icofont-instagram"></i></a>
                <a href=""><i class="icofont-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/team-3.jpg" alt="">
              <h4>William Anderson</h4>
              <span>CTO</span>
              <p>
                Voluptas necessitatibus occaecati quia. Earum totam consequuntur qui porro et laborum toro des clara
              </p>
              <div class="social">
                <a href=""><i class="icofont-twitter"></i></a>
                <a href=""><i class="icofont-facebook"></i></a>
                <a href=""><i class="icofont-instagram"></i></a>
                <a href=""><i class="icofont-linkedin"></i></a>
              </div>
            </div>
          </div>

        </div>
      -->

      </div>
    </section><!-- End Our Team Section -->


    <!-- ======= Contact Us Section ======= -->
    <!--
    <section id="contact" class="contact section-bg">
      <div class="container">

        <div class="section-title">
          <h2>Contact Us</h2>
          <p>Magnam dolores commodi suscipit. Necessitatibus eius consequatur ex aliquid fuga eum quidem. Sit sint consectetur velit. Quisquam quos quisquam cupiditate. Et nemo qui impedit suscipit alias ea. Quia fugiat sit in iste officiis commodi quidem hic quas.</p>
        </div>

        <div class="row">

          <div class="col-lg-4 col-md-6">
            <div class="contact-about">
              <h3>Amoeba</h3>
              <p>Cras fermentum odio eu feugiat. Justo eget magna fermentum iaculis eu non diam phasellus. Scelerisque felis imperdiet proin fermentum leo. Amet volutpat consequat mauris nunc congue.</p>
              <div class="social-links">
                <a href="#" class="twitter"><i class="icofont-twitter"></i></a>
                <a href="#" class="facebook"><i class="icofont-facebook"></i></a>
                <a href="#" class="instagram"><i class="icofont-instagram"></i></a>
                <a href="#" class="linkedin"><i class="icofont-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-3 col-md-6">
            <div class="info">
              <div>
                <i class="icofont-google-map"></i>
                <p>A108 Adam Street<br>New York, NY 535022</p>
              </div>

              <div>
                <i class="icofont-envelope"></i>
                <p>info@example.com</p>
              </div>

              <div>
                <i class="icofont-phone"></i>
                <p>+1 5589 55488 55s</p>
              </div>

            </div>
          </div>

          <div class="col-lg-5 col-md-12">
            <form action="forms/contact.php" method="post" role="form" class="php-email-form">
              <div class="form-group">
                <input type="text" name="name" class="form-control" id="name" placeholder="Your Name" data-rule="minlen:4" data-msg="Please enter at least 4 chars" />
                <div class="validate"></div>
              </div>
              <div class="form-group">
                <input type="email" class="form-control" name="email" id="email" placeholder="Your Email" data-rule="email" data-msg="Please enter a valid email" />
                <div class="validate"></div>
              </div>
              <div class="form-group">
                <input type="text" class="form-control" name="subject" id="subject" placeholder="Subject" data-rule="minlen:4" data-msg="Please enter at least 8 chars of subject" />
                <div class="validate"></div>
              </div>
              <div class="form-group">
                <textarea class="form-control" name="message" rows="5" data-rule="required" data-msg="Please write something for us" placeholder="Message"></textarea>
                <div class="validate"></div>
              </div>
              <div class="mb-3">
                <div class="loading">Loading</div>
                <div class="error-message"></div>
                <div class="sent-message">Your message has been sent. Thank you!</div>
              </div>
              <div class="text-center"><button type="submit">Send Message</button></div>
            </form>
          </div>

        </div>

      </div>

    </section>-->
    <!-- End Contact Us Section -->

    <!-- ======= Map Section ======= -->
    <!--
    <section class="map">
      <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3024.2219901290355!2d-74.00369368400567!3d40.71312937933185!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x89c25a23e28c1191%3A0x49f75d3281df052a!2s150%20Park%20Row%2C%20New%20York%2C%20NY%2010007%2C%20USA!5e0!3m2!1sen!2sbg!4v1579767901424!5m2!1sen!2sbg" frameborder="0" style="border:0;" allowfullscreen=""></iframe>-->
    </section><!-- End Map Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <!--
  <footer id="footer">
    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>Amoeba</span></strong>. All Rights Reserved
      </div>
      <div class="credits">-->
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/free-one-page-bootstrap-template-amoeba/ -->
        <!--Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>
  </footer>--><!-- End #footer -->

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>

