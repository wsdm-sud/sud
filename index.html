<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>SUD 2021</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/conversation.jpg" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Lato:400,300,700,900" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/animate.css/animate.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Amoeba - v2.0.0
  * Template URL: https://bootstrapmade.com/free-one-page-bootstrap-template-amoeba/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->

<style>
.dropdown-menu {
    background: #1d443f;
}
</style>
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container">

      <div class="logo float-left">
        <!--h1 class="text-light"><a href="index.html"><span>SUD-2021</span></a></h1-->
        <!-- Uncomment below if you prefer to use an image logo -->
        <!-- <a href="index.html"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->
      </div>

      <nav class="nav-menu float-right d-none d-lg-block">
        <ul>
          <li class="active"><a href="#header">Home</a></li>
          <li><a href="#about">Motivation & Description</a></li>
          <li><a href="#papers">Call for Papers</a></li>
          <!--<li><a href="#dtrack">Data Challenge Track</a></li>-->
          <li class="nav-item dropdown">
           <a class="nav-link dropdown-toggle" href=""  
               id="navbarDropdown" role="button" data-toggle="dropdown" aria-expanded="true">
          Data Challenge Track </a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
            <a class="dropdown-item" href="#dtrack">Overview</a>
            <a class="dropdown-item" href="https://rcd2020firetask.github.io/RCD2020FIRETASK/#services" target="_blank">Tasks</a>
            <a class="dropdown-item" href="https://rcd2020firetask.github.io/RCD2020FIRETASK/#dataset" target="_blank">Dataset</a>
          </div>
          </li>
          <li><a href="#guidelines">Submission Guidelines</a></li>
          <li><a href="#impdates">Important Dates</a></li>
          <li><a href="#program">Program</a></li>
          <!--li><a href="#contact1">Results</a></li-->
          <li><a href="#team">Organizers</a></li>
        </ul>
      </nav><!-- .nav-menu -->

    </div>
  </header><!-- End #header -->

  <!-- ======= Hero Section ======= -->
  <section id="hero">
    <div class="hero-container">
    <!--div class="call-to-action"-->
      <h2>First International Workshop on </h2>
      <h1><b>S</b>upporting and <b>U</b>nderstanding of Conversational <b>D</b>ialogues <br> (<b>SUD-2021</b>) </h1>
      <h2>Workshop at 14th ACM International Conference on Web Search and Data Mining (<b>WSDM 2021</b>)</h2>
      <a href="#about" class="btn-get-started scrollto">Get Started</a>
    </div>
  </section><!-- #hero -->

  <main id="main">

    <!-- ======= About Us Section ======= -->
    <section id="about" class="about">
      <div class="container">

        <div class="section-title">
            <h2>Workshop Motivation and Description</h2>
        </div>

        <div class="row" >
         <div class="col-lg-6 order-1 order-lg-2">
            <img src="assets/img/conversations.png" class="img-fluid" alt="">
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 order-2 order-lg-1">
            <h3>Motivation</h3>
            <p class="description">
            Verbal communication in the form of spoken dialogues is the most natural and prevalent medium of information exchange between humans. 
              Meetings, prevalent in enterprise environments, are a common communication channel to reach the collective agreements on decision making. 
              Another useful application area of analysis of conversational dialogues is the customer care, where a customer usually interacts with a 
              human or an automated agent (a chatbot) to work towards a specific task. e.g. troubleshoot a Linux workstation etc. 


              <!--A variety of automated processing on the transcripts of these conversational dialogues can be useful in practice, e.g., identification 
              of action items from meetings (specifically, the alternatives discussed and the criteria for each alternative) can help develop effective 
              decision making support systems in enterprises as well as in end-user scenarios. Moreover, applications of NLP and IR methodologies in 
              dialogue based interactive systems, e.g. the need to summarize the meetings, allow provision for ad hoc search on meetings effectively 
              indexing these meetings so that they can be retrieved has increasingly drawn attention from the research community-->.

            </p>
            <br>
        </div>
        </div>

        <div>
            <h3>Description</h3>
            <p class="description">
            There are several open problems in this domain that require an in-depth research such as understanding the <b>nature of conversations</b>, their <b>underlying intent</b> and <b>evaluating</b> the quality of new <b>conversational search tools/algorithms</b>.
            The workshop aims to accomplish the following two goals.
            <ol>
            <li>Gather researchers from the IR and NLP communities to present their recent work on the topic and
            <li>Provide a platform for new PhD students or early researchers to build and evaluate conversational systems on labeled data.
            </ol>

            </p>
            <p>
            The first objective of the proposed <b>SUD workshop series</b> is to bring together researchers from diverse fields – Information Retrieval, Data Mining and Machine Learning, Natural Language Processing, Human Computer Interaction etc. to further advance the state of research in applications and impact of information retrieval to digital two-party or multi-party text or multi-modal dialogues. Given the diverse audience, participants and program of WSDM, it would be an ideal venue to advance research on such topics.

            </p>
            <p>The second objective is to invite PhD students and new researchers to conduct research on an open dataset and discuss their findings with experts at the workshop. We specifically encourage research on a recently released dataset containing conversations extracted from movies, labeled with entities of interest and wikipedia passages relevant to the corresponding entities that add more context. The dataset, released as part of <a href='https://rcd2020firetask.github.io/RCD2020FIRETASK/' target="_blank">RCD Track at FIRE 2020</a>, aims to explore the utility of IR systems to fetch more information about entities discussed in these dialogues.</p>
            <!--p>
            It has been established that IR systems can be used to retrieve relevant information either to generate replies in conversations or to add more context about a particular topic during an interactive dialogue between two entities. In addition to inviting work on
            <b>conversational IR </b> and <b>conversational assistive technologies</b>, we specifically focus on an interesting and timely research question that we seek to address as a part of our
data challenge track.
While the regular track invites submissions on both the understanding on and the supporting of conversational dialogues, the data challenge track specifically focuses on the latter. In particular, in order to support conversational dialogues we explore the utility of IR systems to retrieve more information about entities discussed in interactive dialogues. As a continuation of our shared task - RCD1(Retrieval from Conversational Dialogues) organized at FIRE 2020, a large dataset of conversations annotated with underlying user intent is made available. Participants will thus be invited to develop methods for solving practical challenges on the dataset which include detecting user intent in dialogues and retrieving useful information to support these intents.
            </p-->

           
      </div>

    </section><!-- End About Us Section -->

    <!-- ======= Services Section ======= -->
    <section id="papers" class="portfolio section-bg">
    <div class="container">
      <h1> Research track call for papers</h1> 
        The proposed workshop will consist of two tracks a) Research track and b) Data challenge track. 
        Research paper track invites submissions from themes and topics aligned with research in Conversational Dialogues. 

        The following topics associated with Intelligent Assistants are particularly of interest for SUD 2021 workshop: 
        <ul>
        <li>Voice search</li>
        <ul><li>conversational search</li> <li>dialog systems</li></ul>
        <li>Personal assistants</li>
        <ul><li>dialogue models</li> <li>conversational interaction</li></ul>
        <!--li>Task-driven search</li>
        <ul><li>Zero-query</li> <li> Implicit search </li> </ul-->
        </ul>

        <!--For authors whose work hasn't been accepted in the main conference, this is a good chance for them to reshape their work and send it to this workshop
        so as to foster discussions on this emerging topic.
        For authors whose papers have already been accepted in the WSDM main conference, they could submit a new work-in-progress
        aligned with their paper in the main conference. -->

        We also invite contributions related to the main theme of <b>supporting and understanding of conversational dialogues</b>, which includes (but is not limited to):
                <menu>
                  <li> New datasets: mining and extracting conversational dialogues from the web. </li>
                   <li> Addressing the code-mixed, noisy and informal vocabulary of conversations.</li>
                   <!--<li> Transfer learning – applying models trained on prior datasets to different conversations.</li> -->
                   <li> Summarization of conversational dialogues.</li>
                   <li> Entity linking and information Extraction from conversational dialogues, e.g.extracting action-items, decisions and their criteria from group meetings.</li>
                   <li> <b>Conversational IR</b>, covering the following topics:
                     <ul>
                        <li> Retrieving relevant pieces of information corresponding to information needs arising out from conversations.</li>
                        <li> Retrieve information from multiple online and offline data sources (including text, images, and video) to support conversations.</li>
                        <li> Ways of presenting relevant information through interactive dialogues.</li>
                        <li> Asking clarifying questions to enrich information need description.</li>
                     </ul>
                  </li>
                  <li><b>Data challenge track</b> invites submissions on the following topics:
                    <ul>
                    <li> Methods for passage retrieval supporting conversations</li>
                    <li> Graph-based techniques (e.g. Graph Convolutional Networks) to understand conversations</li>
                    <li> Adaptation of large scale models, e.g.transformers to contextualize conversations better.</li>
                    </ul>
                  </li>
                </menu>
    </div>
  </section>
        <section id="dtrack" class="program">
        <div class="container">
          <h1> Data Challenge Track</h1> 
           <p>The data challenge track is a continuation of our effort to investigate the research question of contextualization of conversational 
           dialogues. A shared task was recently organized - <b>Retrieval from Conversational Dialogues (<a href="https://rcd2020firetask.github.io/RCD2020FIRETASK/" target="_blank">RCD</a>) </b> at FIRE 2020.
            </p>
                Data challenge track seeks submissions that investigate both understanding of sample dialogues and support such conversations with more contextual information. 
                As part of the challenge, we are releasing conversational data for <a href='https://rcd2020firetask.github.io/RCD2020FIRETASK/#services' target="_blank">two tasks</a>. The first task is to detect entities in these conversations. The second task is to retrieve informative content about these 
                entities to facilitate user understanding. Although prior work has looked into contextualizing short documents, such as 
                tweets, the proposed data challenge track requires contextualizing aspects of a conversation.
            </p>
            <br>
            <p>
            Papers submitted to this track <b>must</b> report at least one experiment with the <a href="https://rcd2020firetask.github.io/RCD2020FIRETASK/#dataset" target="_blank">dataset released as a part of the RCD track</a>. Authors are encouraged to either
            experiment and report results for the two RCD tasks - that of detecting entities in the text spans from movie dialogues or of retrieving relevant information given a dialog context, or reporting experiments on <b>novel tasks on this dataset</b>. 
            </p>

        </div>
      </section>
      <section id="guidelines" class="portfolio section-bg">
          <div class="container">
        <h2> Submission Guidelines </h2>
        <br>
        Papers submitted for both the <b>regular research</b> and the <b>data challenge</b> tracks should be 4-6 pages of length of content (plus 1 additional page for references). 
Papers must be submitted in PDF according to the new ACM format published in ACM guidelines, selecting the generic <a href="https://www.acm.org/publications/taps/word-template-workflow">sigconf template</a>. The review process is single-blind and therefore submissions should contain author information. Paper should be uploaded via Easychair via this <a href="https://easychair.org/my/conference?conf=sudwsdm2021#">submission link</a>.

Accepted papers will be included in the SUD 2021 proceedings (companion volume of WSDM 2021) and at least one author of each accepted contribution must attend the workshop.
After acceptance, no additional authors can be added.

        </div>
      </section>
    <section id="impdates" class="program">
      <div class="container">

        <!--div class="section-title"-->
        <h2>Important Dates</h2>


        <ul>
          <li> Submission deadline - 26th January, 2021 </li>
          <li> Notifications- 23rd February, 2021 </li>
          <li> Camera-Ready - 2nd March, 2021 </li>
          <li> Workshop day- 12th March, 2021 </li>
          
          <!--li> Workshop -  March 12, 2021</li-->
        <!--li><strike>Training Data Release</strike> (<a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/tree/master/Train">Download link</a>)-	16th July, 2020   &nbsp;&#10003;</li> 
        <li><strike>Test Data Release</strike> (<a href="https://github.com/rcd2020firetask/RCD2020FIRETASK/blob/master/test.txt">Download link</a>) -	16th July, 2020 &nbsp;&#10003;</li>
        <li>Run Submission Deadline -	5th September, 2020 &nbsp;&#10003;</li>
        <li>Results Declaration -	15th September, 2020 &nbsp;&#10003;</li>
        <li>Working Note Submission -	8th October, 2020</li>
        <li>Review Notifications -	25th October, 2020</li>
        <li>Final Version of Working Note - 5th November, 2020    </li-->    
        </ul>
        
        </div>
      </div>
    </section>


    </section>
        <section id="program" class="portfolio section-bg">
          <div class="container">
             <p>
                <h2>Program (Tentative Plan)</h2>
             <br>
            <ul>
           <li> 13.00 IST: Introduction --  About 5-10 mins </li>

 <li>13.10 IST: Keynote-1: Jeff Dalton, University of Glasgow --- 1.30 hours.</li>

 <li>14.40 IST: Comfort-break 1 --- 10 mins.</li>

 <li>14.50 IST: Industry Keynote-2: Surbhi Rathore, CEO, Symbl.AI -- 50 mins.</li>

 <li>15.40 IST: Paper presentation -- Priyanka Sinha, IIT-KGP, India --- 20 mins.</li>

 <li>16.00 IST: Comfort-break 2 --- 10 mins</li>

 <li>16.10 IST: RCD track overview and lessons learnt -- Manisha Verma, Verizon Media --- 20 mins </li>

 <li>16.30 IST: Panel discussion --- 30 mins.</li>

 <li>17.00 IST: Closing remarks -- 5 mins.</li>
              </ul>            
         </p>
 <p><h3>Keynote Talk</h3></br>
<img src="https://www.gla.ac.uk/media/Media_764764_smxx.jpg" class="rounded float-left" alt="picture" style="width:200px;height:200px;">
          <b> Jeff Dalton (University of Glasgow)</b>
Dr. Jeff Dalton is an Assistant Professor (Lecturer) in the School of Computing Science at the University of Glasgow where he leads the Glasgow Representation and Information Learning Lab (GRILL). His research focuses on text understanding and conversational information seeking. He completed his PhD at the University of Massachusetts Amherst in the Center for Intelligent Information Retrieval. Later in Google Research, he worked on Information Extraction as part of the Knowledge Discovery Team (Knowledge Vault) and language understanding in the Assistant Response Ranking team. He is the lead organizer for the TREC Conversational Assistance Track (CAsT) (http://treccast.ai) and previously helped organize the Complex Answer Retrieval track. He is the recipient of a prestigious UKRI Turing AI Acceleration Fellowship and received research awards from Google, Amazon, and Bloomberg. He holds multiple patents in retrieval and question answering systems.
          </br></br>
         <b> Title: Conversation Search: Current Challenges and Future Directions </b>
</br></br>
<b>Abstract: </b>This talk examines some of the fundamental challenges in Conversational Information Seeking (CIS). It describes lessons learned developing recent conversational search benchmarks (TREC CAsT and ConvAI3) and open research challenges. It also presents work from the Glasgow Representation and Information Learning Lab (GRILL) on neural models for conversational rewriting, entity-based ranking, and the use of feedback and initiative in CIS.
</br>
    
          
          </p>
 </p>
 <p><h3>Invited Talk</h3></br>
<img src="assets/img/surbhi.jpg" class="rounded float-left" alt="picture" style="width:200px;height:200px;">
          <b> Surbhi Rathore (Symbl.ai)</b>
Surbhi is the CEO and Co-founder of Symbl.ai. Symbl is bringing to life her vision for a programmable platform that empowers developers and businesses to build unique conversational experiences without the hassle of upfront training or building their in-house data science expertise. She co-founded Symbl almost 2 years ago and backed by Amazon and a Techstars alum. Symbl raised an early-stage venture round of $6.5M and deployed capital to grow a team of tech enthusiasts to 30 people primarily distributed between India and Seattle. She comes with experience from technical and customer-obsessed roles in both startups and enterprises such as Nevis Networks and Amdocs. Before co-founding Symbl, she worked in the Conversational AI space with a focus on delivering value to Telecommunication users. She is an advocate for Women in AI with a personal mission to inspire more women to work in Data Science. In her free time, she loves to travel and spend time with her remote and distributed family.
          </br></br>
         <b> Title: Conversation intelligence for the growing digital ecosystem </b>
</br></br>
<b>Abstract: </b> 
Now more than ever, when the whole world is communicating on digital channels, the dangers of disconnected data silos and lost knowledge are more than ever. In this session, we will talk about applying AI/ML to human conversations at scale so that builders can strategize product strategy early in the life cycle of their business and future-proof growth. The session also entails several dimensions of conversation intelligence that can amplify customer experiences, superpower productivity and drive growth opportunities for businesses for several mission critical use cases. 
</br>
    
          
          </p>
      </div>
    </section>

    <section id="team" class="call-to-action">
      <div class="container">

          <h2>Organizers</h2>

        <div class="row">
          <div class="col-lg-12">
            <ul>
              <li><b><a href='https://gdebasis.github.io/'>Debasis Ganguly </a></b>, IBM Research, Ireland</li>
              <li><b><a href='https://research.yahoo.com/researchers/manishav'>Manisha Verma</a></b>, Yahoo! Research, New York</li>
              <li><b><a href='https://computing.dcu.ie/~sprocheta'>Procheta Sen</a>,</b> Dublin City University, Ireland</li>             
              <li><b><a href='https://computing.dcu.ie/~gjones'>Gareth J.F. Jones</a>,</b> Dublin City University, Ireland</li>             
              <li><b><a href='https://www.isical.ac.in/~dipasree_t/'>Dipasree Pal </a></b>, ISI, Kolkata, India</li>
              </ul>
          </div>
        </div>


        <div class="section-title">
          <h4>Contact US</h4>
          <p>Please reach out to the organizers for any questions. For further questions and clarifications, please mail to <a href="mailto:wsdmconf@gmail.com">wsdmconf@gmail.com</a>.</p>
        </div>

      </div>
    </section>  <!-- End Our Portfolio Section -->

  <!-- ======= Footer ======= -->
  <!--
  <footer id="footer">
    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>Amoeba</span></strong>. All Rights Reserved
      </div>
      <div class="credits">-->
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/free-one-page-bootstrap-template-amoeba/ -->
        <!--Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>
  </footer>--><!-- End #footer -->

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>

